{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, distutils.core\n",
    "import torch, detectron2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIm = cv2.imread(\"images/personTest.jpg\")\n",
    "def crop(image, box):\n",
    "  box = list(map(round, box))\n",
    "  return image[box[1]:box[3],box[0]:box[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/12 09:32:10 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(testIm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 63, 67, 41, 63, 56, 56, 56, 60, 62,  0, 56, 66, 62, 56],\n",
      "       device='cuda:0')\n",
      "Boxes(tensor([[176.8925, 128.9994, 442.2191, 558.4124],\n",
      "        [318.5848, 328.7300, 608.0167, 527.5706],\n",
      "        [281.6033, 469.0381, 389.1134, 538.0613],\n",
      "        [712.3412, 255.5654, 736.3952, 292.0757],\n",
      "        [640.4684, 359.5596, 750.0000, 559.3851],\n",
      "        [545.6935, 302.9352, 724.0679, 421.3087],\n",
      "        [606.0677, 237.1271, 642.6721, 281.5972],\n",
      "        [629.0142, 223.1486, 664.2052, 281.1701],\n",
      "        [569.3185, 279.2024, 750.0000, 315.0801],\n",
      "        [ 53.7917,   1.7764, 387.1675, 227.8983],\n",
      "        [433.2606, 260.1226, 545.5934, 407.7874],\n",
      "        [ 48.0880, 336.0539, 206.6906, 563.0000],\n",
      "        [353.1082, 432.7774, 454.2135, 511.1516],\n",
      "        [554.8609, 142.3699, 571.1406, 205.0274],\n",
      "        [643.4143, 220.1219, 660.9359, 270.4447]], device='cuda:0'))\n",
      "torch.Size([563, 750])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[\"instances\"].pred_classes)\n",
    "print(outputs[\"instances\"].pred_boxes)\n",
    "classes = outputs['instances'].pred_classes.to('cpu')\n",
    "boxes = outputs['instances'].pred_boxes.to('cpu')\n",
    "boxesNp = boxes.tensor.numpy()\n",
    "masks = outputs['instances'].pred_masks.to('cpu')\n",
    "print(masks[0].shape)\n",
    "box1 = list(map(round, boxesNp[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 750, 3)\n",
      "66908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 506ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:33:45.145276\n",
      "colors:  {'beige': 4.850890491070459e-06, 'black': 3.575502205421799e-06, 'blue': 0.9992419481277466, 'brown': 1.352603362647642e-06, 'gold': 1.934447391249705e-05, 'green': 1.9015509678865783e-05, 'grey': 8.848131756167277e-07, 'orange': 0.0006274095503613353, 'pink': 1.7279497797062504e-06, 'purple': 7.076271799633105e-07, 'red': 2.8785383619833738e-05, 'silver': 2.2900569547346095e-06, 'tan': 8.387011689592327e-07, 'white': 2.4718242457311135e-06, 'yellow': 4.484656892600469e-05}\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:33:53.649107\n",
      "colors:  {'beige': 4.850890491070459e-06, 'black': 3.575502205421799e-06, 'blue': 0.9992419481277466, 'brown': 1.352603362647642e-06, 'gold': 1.934447391249705e-05, 'green': 1.9015509678865783e-05, 'grey': 8.848131756167277e-07, 'orange': 0.0006274095503613353, 'pink': 1.7279497797062504e-06, 'purple': 7.076271799633105e-07, 'red': 2.8785383619833738e-05, 'silver': 2.2900569547346095e-06, 'tan': 8.387011689592327e-07, 'white': 2.4718242457311135e-06, 'yellow': 4.484656892600469e-05}\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:05.385304\n",
      "colors:  {'beige': 1.0384754205006175e-05, 'black': 6.090001534175826e-06, 'blue': 0.9985621571540833, 'brown': 2.3312777557293884e-06, 'gold': 3.4488719393266365e-05, 'green': 2.896190017054323e-05, 'grey': 1.1894562703673728e-06, 'orange': 0.0011997547699138522, 'pink': 2.8622996524063637e-06, 'purple': 1.3141168437869055e-06, 'red': 6.24084277660586e-05, 'silver': 4.2139495235460345e-06, 'tan': 1.268328105652472e-06, 'white': 4.571538738673553e-06, 'yellow': 7.803919288562611e-05}\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:05.506337\n",
      "colors:  {'beige': 0.00021884316811338067, 'black': 5.050216714153066e-05, 'blue': 0.9860376715660095, 'brown': 4.069900023750961e-05, 'gold': 0.0008488615858368576, 'green': 0.00016313900414388627, 'grey': 5.776801117463037e-06, 'orange': 0.010715220123529434, 'pink': 3.707432188093662e-05, 'purple': 1.8701633962336928e-05, 'red': 0.0004903689259663224, 'silver': 1.2719832739094272e-05, 'tan': 1.013489963952452e-05, 'white': 1.1841531886602752e-05, 'yellow': 0.0013383133336901665}\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:05.629136\n",
      "colors:  {'beige': 5.078712547401665e-06, 'black': 4.004712081950856e-06, 'blue': 0.9994076490402222, 'brown': 1.866857587629056e-06, 'gold': 2.1163097699172795e-05, 'green': 1.642768256715499e-05, 'grey': 6.401858740900934e-07, 'orange': 0.000473341322503984, 'pink': 1.6808683085400844e-06, 'purple': 6.396774665518024e-07, 'red': 2.8876582291559316e-05, 'silver': 2.2144781723909546e-06, 'tan': 6.574776989509701e-07, 'white': 1.8216703665530076e-06, 'yellow': 3.404024391784333e-05}\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:05.765664\n",
      "colors:  {'beige': 4.010277734778356e-06, 'black': 6.771240350644803e-06, 'blue': 0.999043881893158, 'brown': 1.0799426490848418e-06, 'gold': 1.1197806088603102e-05, 'green': 1.774307747837156e-05, 'grey': 3.577856432457338e-06, 'orange': 0.0007970960577949882, 'pink': 1.957150288944831e-06, 'purple': 9.994134870794369e-07, 'red': 3.935535278287716e-05, 'silver': 3.011050466739107e-06, 'tan': 1.2941710565428366e-06, 'white': 2.4515738914487883e-06, 'yellow': 6.558278255397454e-05}\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:05.912014\n",
      "colors:  {'beige': 0.0004821554757654667, 'black': 9.269443398807198e-05, 'blue': 0.9871856570243835, 'brown': 3.542616468621418e-05, 'gold': 0.0007973054889589548, 'green': 0.0004692508664447814, 'grey': 2.103254882968031e-05, 'orange': 0.009632320143282413, 'pink': 5.301513374433853e-05, 'purple': 1.3881105587643106e-05, 'red': 0.00021033443044871092, 'silver': 2.3887840143288486e-05, 'tan': 2.304318877577316e-05, 'white': 5.58744759473484e-05, 'yellow': 0.0009040420409291983}\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:06.036390\n",
      "colors:  {'beige': 4.985532541468274e-06, 'black': 3.6298411032475997e-06, 'blue': 0.9990988969802856, 'brown': 1.358235294901533e-06, 'gold': 2.49775403062813e-05, 'green': 2.2917205569683574e-05, 'grey': 9.003330774248752e-07, 'orange': 0.0007317332783713937, 'pink': 2.3798133952368516e-06, 'purple': 8.032708933569666e-07, 'red': 3.3884134609252214e-05, 'silver': 3.517656068652286e-06, 'tan': 8.295087354781572e-07, 'white': 2.4825612854328938e-06, 'yellow': 6.671797018498182e-05}\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:06.209156\n",
      "colors:  {'beige': 8.25753522804007e-06, 'black': 6.818781912443228e-06, 'blue': 0.9987727999687195, 'brown': 1.729421342133719e-06, 'gold': 3.825057501671836e-05, 'green': 3.315385038149543e-05, 'grey': 2.1531927814066876e-06, 'orange': 0.0009839227423071861, 'pink': 3.263491407778929e-06, 'purple': 1.1657174354695599e-06, 'red': 5.992884689476341e-05, 'silver': 4.275936589692719e-06, 'tan': 1.3948591686130385e-06, 'white': 3.633130063462886e-06, 'yellow': 7.920965435914695e-05}\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:06.409618\n",
      "colors:  {'beige': 7.0392611632996704e-06, 'black': 4.824310963158496e-06, 'blue': 0.9990901947021484, 'brown': 1.8994596757693216e-06, 'gold': 3.421237488510087e-05, 'green': 2.888720882765483e-05, 'grey': 1.3988518503538216e-06, 'orange': 0.0007065565441735089, 'pink': 2.90845400741091e-06, 'purple': 1.0535510455156327e-06, 'red': 3.974124774686061e-05, 'silver': 4.186695605312707e-06, 'tan': 1.4329604027807363e-06, 'white': 3.958138222515117e-06, 'yellow': 7.168694719439372e-05}\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:06.592773\n",
      "colors:  {'beige': 2.635605369505356e-06, 'black': 4.778312359121628e-06, 'blue': 0.9992380142211914, 'brown': 7.387330356323218e-07, 'gold': 1.5588982932968065e-05, 'green': 2.551226134528406e-05, 'grey': 8.419972346018767e-07, 'orange': 0.0006332961493171751, 'pink': 2.0353584204713115e-06, 'purple': 6.413022788365197e-07, 'red': 2.1476163965417072e-05, 'silver': 3.026954118467984e-06, 'tan': 6.646317842751159e-07, 'white': 4.057498244947055e-06, 'yellow': 4.668809560826048e-05}\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:06.776431\n",
      "colors:  {'beige': 5.58011197426822e-06, 'black': 4.238640940457117e-06, 'blue': 0.9992109537124634, 'brown': 1.4388676845555892e-06, 'gold': 1.6863323253346607e-05, 'green': 2.4915865651564673e-05, 'grey': 9.19679848720989e-07, 'orange': 0.000644445070065558, 'pink': 1.6562117934881826e-06, 'purple': 7.433013706759084e-07, 'red': 3.327183731016703e-05, 'silver': 1.8376230173089425e-06, 'tan': 6.911627679073717e-07, 'white': 1.7447314348828513e-06, 'yellow': 5.063850403530523e-05}\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 09:34:06.898308\n",
      "colors:  {'beige': 4.669572263082955e-06, 'black': 3.2166180972126313e-06, 'blue': 0.9993264675140381, 'brown': 1.053786149896041e-06, 'gold': 1.5526264178333804e-05, 'green': 1.6959660570137203e-05, 'grey': 8.594290079599887e-07, 'orange': 0.0005584691534750164, 'pink': 1.5632741678928141e-06, 'purple': 5.793328341496817e-07, 'red': 2.560075154178776e-05, 'silver': 2.31085641644313e-06, 'tan': 7.260968573064019e-07, 'white': 2.705553015402984e-06, 'yellow': 3.9356124034384266e-05}\n"
     ]
    }
   ],
   "source": [
    "im= testIm\n",
    "\n",
    "i = 0\n",
    "im2 = crop(im, boxesNp[i])\n",
    "#cv2.imshow('image',im2)\n",
    "cv2.waitKey(0)\n",
    "print(im.shape)\n",
    "\n",
    "aMask = masks[i].unsqueeze(-1).numpy()\n",
    "print(np.sum(aMask[:,:,0]))\n",
    "\n",
    "im3 = crop(im*aMask,boxesNp[i])\n",
    "#cv2.imshow(\"kasdfl\",im3)\n",
    "cv2.imwrite('testOut2.jpg', im3)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Visualizer(testIm[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow('Visualiser', out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jean-Luc\\Documents\\PolyMtl\\Git\\.default\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `enable_queue` is deprecated in `Interface()`, please use it within `launch()` instead.\n",
      "  warnings.warn(value)\n",
      "c:\\Users\\Jean-Luc\\Documents\\PolyMtl\\Git\\.default\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Interface, please remove them: {'debug': True}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"simple-CNN-model.2022-8-9.hdf5\")\n",
    "\n",
    "def image_predict(img):\n",
    "    \"\"\"\n",
    "    Displays dominant colors beyond a given threshold.\n",
    "    img : image input, for ex 'blue-car.jpg'\n",
    "    isize: input image size, for ex. 227\n",
    "    thr: chosen threshold value\n",
    "    \"\"\"\n",
    "    thr=0\n",
    "    global model\n",
    "    if model is None:\n",
    "        model = tf.keras.models.load_model(\"models/simple-CNN-model.2022-8-9.hdf5\")\n",
    "        \n",
    "    data = np.asarray(img)\n",
    "        \n",
    "    ndata = np.expand_dims(data, axis=0)\n",
    "    y_prob = model.predict(ndata/255)\n",
    "    #y_prob.argmax(axis=-1)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    print(\"--------\")\n",
    "    print(\"data and time: \", now)\n",
    "            \n",
    "    colorlabels = ['beige', 'black', 'blue', 'brown', 'gold', 'green', 'grey', 'orange', 'pink', 'purple', 'red', 'silver', 'tan', 'white', 'yellow']\n",
    "    coltags = [sorted(colorlabels)[i] for i in np.where(np.ravel(y_prob)>thr)[0]]\n",
    "    colprob = [np.ravel(y_prob)[i] for i in list(np.where(np.ravel(y_prob)>thr)[0])]\n",
    "    \n",
    "    if len(coltags) > 0:\n",
    "        response = []\n",
    "        for i,j in zip(coltags, colprob):\n",
    "            #print(i,j)\n",
    "            resp = {}\n",
    "            resp[i] = float(j)\n",
    "            response.append(resp)\n",
    "        d = dict(map(dict.popitem, response))\n",
    "        print('colors: ', d)\n",
    "               \n",
    "        return dict(d)\n",
    "\n",
    "    else:\n",
    "        return str('No label was found')\n",
    "\n",
    "iface = gr.Interface(\n",
    "    title = \"Object color tagging\",\n",
    "    description = \"App classifying objects on different colors\",\n",
    "    article = \"<p style='text-align: center'><a href='https://www.rrighart.com' target='_blank'>Webpage</a></p>\",\n",
    "    fn=image_predict,\n",
    "    inputs=gr.Image(shape=(227,227)), \n",
    "    outputs=gr.Label(),\n",
    "    enable_queue=True,\n",
    "    interpretation=\"default\",\n",
    "    debug=True\n",
    "    )\n",
    "#iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 97ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 10:08:31.027726\n",
      "colors:  {'beige': 4.560923116514459e-06, 'black': 3.6461119634623174e-06, 'blue': 0.9992368221282959, 'brown': 1.3800082570014638e-06, 'gold': 1.9600100131356157e-05, 'green': 2.0290563043090515e-05, 'grey': 8.125386443680327e-07, 'orange': 0.0006298327934928238, 'pink': 1.7705516484056716e-06, 'purple': 6.388135034285369e-07, 'red': 3.0910778150428087e-05, 'silver': 2.0637364741560305e-06, 'tan': 7.819139682396781e-07, 'white': 2.6793827601068188e-06, 'yellow': 4.4230586354387924e-05}\n",
      "('blue', 0.9992368221282959)\n"
     ]
    }
   ],
   "source": [
    "def cropSquare(im):\n",
    "    dim = min(im.shape[0], im.shape[1])\n",
    "    if im.shape[0] > im.shape[1]:\n",
    "        left = round((im.shape[0]-dim)//2)\n",
    "        return im[left:left+dim]\n",
    "    left = round((im.shape[1]-dim)//2)\n",
    "    return im[:,left:left+dim]\n",
    "\n",
    "resizeim3 = cv2.resize(cropSquare(im3), (227,227))\n",
    "resizeim3 = cv2.cvtColor(resizeim3, cv2.COLOR_BGR2RGB)\n",
    "#cv2.imshow('Visualiser', resizeim3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def getBest(dct):\n",
    "    best = None\n",
    "    val = 0\n",
    "    for item in dct:\n",
    "        if dct[item] > val:\n",
    "            best = item\n",
    "            val = dct[item]\n",
    "    return best, val\n",
    "\n",
    "\n",
    "ans = getBest(image_predict(resizeim3))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItem(image):\n",
    "    outputs = predictor(image)\n",
    "    classes = outputs['instances'].pred_classes.to('cpu')\n",
    "    boxes = outputs['instances'].pred_boxes.to('cpu')\n",
    "    boxesNp = boxes.tensor.numpy()\n",
    "    masks = outputs['instances'].pred_masks.to('cpu')\n",
    "\n",
    "    done = False\n",
    "    i = 0\n",
    "    while not done and i < 10:\n",
    "        aMask = masks[i].unsqueeze(-1).numpy()\n",
    "        im3 = crop(image*aMask,boxesNp[i])\n",
    "        resizeim3 = cv2.resize(cropSquare(im3), (227,227))\n",
    "        resizeim3 = cv2.cvtColor(resizeim3, cv2.COLOR_BGR2RGB)\n",
    "        color, val = getColor(resizeim3)\n",
    "        if val > 0.8:\n",
    "            done = True\n",
    "        i += 1\n",
    "\n",
    "    if not done:\n",
    "        return (None, None, None)\n",
    "    return color, classes[i], im3\n",
    "\n",
    "def getColor(image):\n",
    "    pred = image_predict(image)\n",
    "    return getBest(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "--------\n",
      "data and time:  2023-02-12 10:13:43.749668\n",
      "colors:  {'beige': 4.560923116514459e-06, 'black': 3.6461119634623174e-06, 'blue': 0.9992368221282959, 'brown': 1.3800082570014638e-06, 'gold': 1.9600100131356157e-05, 'green': 2.0290563043090515e-05, 'grey': 8.125386443680327e-07, 'orange': 0.0006298327934928238, 'pink': 1.7705516484056716e-06, 'purple': 6.388135034285369e-07, 'red': 3.0910778150428087e-05, 'silver': 2.0637364741560305e-06, 'tan': 7.819139682396781e-07, 'white': 2.6793827601068188e-06, 'yellow': 4.4230586354387924e-05}\n",
      "blue\n"
     ]
    }
   ],
   "source": [
    "color, cls, image = getItem(testIm)\n",
    "\n",
    "cv2.imwrite('output.jpg', image)\n",
    "\n",
    "print(color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4204d2694d0be087f42dbc6ed655ec1f9cc641ea611360f1a189c8d2d6bc359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
